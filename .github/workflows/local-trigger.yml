name: Pipeline Trigger (Local)

on:
  push:
    branches:
      - main
      
  pull_request:      

jobs:
  ci:
    runs-on: ubuntu-latest
  
    steps:
    - uses: actions/checkout@v2.4.2

    - name: 'Check if training pipeline has anything changed'
      uses: dorny/paths-filter@v2
      id: training-pipeline-change
      with:
          filters: |
              src:
                - 'training_pipeline/**'

    - name: 'Setup Python 3.9'
      uses: actions/setup-python@v4
      if: steps.training-pipeline-change.outputs.src == 'true'
      with:
        python-version: '3.9'

    - name: 'Authenticate to Google Cloud'
      uses: 'google-github-actions/auth@v0'
      if: steps.training-pipeline-change.outputs.src == 'true'
      with:
        credentials_json: ${{ secrets.GCP_ML_172005 }}

    - name: 'Set up Cloud SDK'
      uses: 'google-github-actions/setup-gcloud@v1'
      if: steps.training-pipeline-change.outputs.src == 'true'

    - name: 'Install required Python packages'
      if: steps.training-pipeline-change.outputs.src == 'true'    
      run: |
        pip install -r requirements.txt

    - name: 'Download temporary dataset'
      if: steps.training-pipeline-change.outputs.src == 'true'
      working-directory: 'training_pipeline'
      run: |
        mkdir local-data
        gcloud storage cp gs://beans-lowres/tfrecords/*-00-*.tfrec local-data/

    - name: 'Compile TFX Training Pipeline'
      if: steps.training-pipeline-change.outputs.src == 'true'    
      working-directory: 'training_pipeline'
      run: |
        tfx pipeline compile \
          --pipeline-path local_runner.py \
          --engine local
          
    - name: 'Create TFX Training Pipeline'
      if: steps.training-pipeline-change.outputs.src == 'true'    
      working-directory: 'training_pipeline'
      run: |
        tfx pipeline create \
          --pipeline-path local_runner.py \
          --engine local
